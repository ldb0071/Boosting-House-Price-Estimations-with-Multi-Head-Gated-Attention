{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training attention based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import tensorflow as tf\n",
    "from train_model import train\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8, 4)\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['axes.facecolor'] = '#ffffff'\n",
    "rcParams['lines.linewidth'] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the file: D:\\Final_file\\ASI-main\\output\\models\\BJ\\asi_BJ_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = r\"D:\\Final_file\\ASI-main\\output\\models\\BJ\\asi_BJ_weights.hdf5\"\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed the file: {file_path}\")\n",
    "else:\n",
    "    print(f\"The file {file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BEST IT\n",
    "\n",
    "hyperparameter={\n",
    "\"num_nearest\":30,\n",
    "\"sigma\":10,\n",
    "\"geointerpolation\": 'asi_multi',\n",
    "'type_compat_funct_eucli':'kernel_gaussiano',\n",
    "'Num_heads':4,\n",
    "\"learning_rate\":0.001,\n",
    "\"batch_size\":32,\n",
    "\"num_neuron\":60,\n",
    "\"num_layers\":3,\n",
    "\"size_embedded\":60,\n",
    "\"num_nearest_geo\":15,\n",
    "\"num_nearest_eucli\":15,\n",
    "\"id_dataset\":'BJ',\n",
    "\"epochs\":200,\n",
    "\"optimier\":'adam',\n",
    "\"validation_split\":0.1,\n",
    "\"label\":'asi_BJ',\n",
    "\"early_stopping\": False,\n",
    "'scale_log':False,\n",
    "\"graph_label\":'matrix',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = train(**hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,\\\n",
    "result,\\\n",
    "fit,\\\n",
    "embedded_train,\\\n",
    "embedded_test,\\\n",
    "predict_regression_train,\\\n",
    "predict_regression_test = spatial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Test ##########################\n",
      "MALE test:.... 4751.664026242338\n",
      "RMSE test:.... 7863.479323742264\n",
      "MAPE test:.... 7.591164363198836\n",
      "################# Train ##########################\n",
      "MALE train:.... 4696.1917338089015\n",
      "RMSE train:.... 7885.88575257439\n",
      "MAPE train:.... 7.326200880747932\n"
     ]
    }
   ],
   "source": [
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models benchmarking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = dataset.X_train,dataset.X_test,dataset.y_train,dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation for Linear Regression\n",
      "Average Test MAE: 15516.859641943287, Best Test MAE: 15510.25690570184\n",
      "Average Test MSE: 422501728.5886174, Best Test MSE: 422159152.18374324\n",
      "Average Test RMSE: 20554.846351967375, Best Test RMSE: 20546.51192255618\n",
      "Average Test R2: 0.3761539363926765, Best Test R2: 0.37665976850460514\n",
      "Average Test MAPE: 25.547598887443872, Best Test MAPE: 25.521808043681737\n",
      "Average Test MALE: 0.23909405064858286, Best Test MALE: 0.23894196734972284\n",
      "\n",
      "\n",
      "Test Set Evaluation for KNN\n",
      "Average Test MAE: 7310.020479859896, Best Test MAE: 7269.561015761821\n",
      "Average Test MSE: 140610870.6633156, Best Test MSE: 137777323.13610506\n",
      "Average Test RMSE: 11857.808890472083, Best Test RMSE: 11737.85854132282\n",
      "Average Test R2: 0.7923806407686466, Best Test R2: 0.7965645229903824\n",
      "Average Test MAPE: 11.294469950766327, Best Test MAPE: 11.224936959737635\n",
      "Average Test MALE: 0.10869885670875852, Best Test MALE: 0.1081307005625147\n",
      "\n",
      "\n",
      "Test Set Evaluation for Decision Tree\n",
      "Average Test MAE: 18241.128226501205, Best Test MAE: 16686.98703973976\n",
      "Average Test MSE: 676083697.2831565, Best Test MSE: 575542429.8698828\n",
      "Average Test RMSE: 25956.022550386908, Best Test RMSE: 23990.465395024807\n",
      "Average Test R2: 0.001726798543220165, Best Test R2: 0.15018127733408382\n",
      "Average Test MAPE: 26.524007448069607, Best Test MAPE: 24.02147840612895\n",
      "Average Test MALE: 0.29294513705794895, Best Test MALE: 0.2724288093780872\n",
      "\n",
      "\n",
      "Test Set Evaluation for Random Forest\n",
      "Average Test MAE: 15383.407206281196, Best Test MAE: 15160.80977939181\n",
      "Average Test MSE: 485727238.01712215, Best Test MSE: 475683808.31514084\n",
      "Average Test RMSE: 22038.352910176087, Best Test RMSE: 21810.176714440917\n",
      "Average Test R2: 0.28279814040977913, Best Test R2: 0.2976277935466509\n",
      "Average Test MAPE: 21.442575801571188, Best Test MAPE: 20.92504317614393\n",
      "Average Test MALE: 0.23775831734088718, Best Test MALE: 0.23359346074019788\n",
      "\n",
      "\n",
      "Test Set Evaluation for SVM\n",
      "Average Test MAE: 14656.32220077064, Best Test MAE: 14644.284709860356\n",
      "Average Test MSE: 425456822.0532721, Best Test MSE: 424758447.8311108\n",
      "Average Test RMSE: 20626.601605019878, Best Test RMSE: 20609.668794794125\n",
      "Average Test R2: 0.3717905851901265, Best Test R2: 0.37282177152603946\n",
      "Average Test MAPE: 22.315151171805724, Best Test MAPE: 22.261274724969034\n",
      "Average Test MALE: 0.2221390815498073, Best Test MALE: 0.22185585497815455\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3066\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 66004.307404\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 65998.368214\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3062\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 65993.494308\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3062\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 65978.805410\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3062\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 66037.512843\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3068\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 66010.269654\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3067\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 66066.609408\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3065\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 65986.819761\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3065\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 65989.987400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3062\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 65928.604933\n",
      "Test Set Evaluation for LightGBM\n",
      "Average Test MAE: 15189.800834563206, Best Test MAE: 14687.374434710384\n",
      "Average Test MSE: 448696221.00719297, Best Test MSE: 423334507.7634354\n",
      "Average Test RMSE: 21179.802764670527, Best Test RMSE: 20575.094356124722\n",
      "Average Test R2: 0.33747638816557435, Best Test R2: 0.37492429406245475\n",
      "Average Test MAPE: 21.091204717078078, Best Test MAPE: 20.486094395600194\n",
      "Average Test MALE: 0.23600789322382276, Best Test MALE: 0.22752144871250618\n",
      "\n",
      "\n",
      "Test Set Evaluation for CatBoost\n",
      "Average Test MAE: 12888.942158262496, Best Test MAE: 12680.457934446982\n",
      "Average Test MSE: 308963968.0083906, Best Test MSE: 299011287.6232209\n",
      "Average Test RMSE: 17576.055042029748, Best Test RMSE: 17291.942852762986\n",
      "Average Test R2: 0.5437984221214703, Best Test R2: 0.5584940791105462\n",
      "Average Test MAPE: 18.178047605553456, Best Test MAPE: 17.87532291689715\n",
      "Average Test MALE: 0.19999788088713416, Best Test MALE: 0.19596106661520638\n",
      "\n",
      "\n",
      "Test Set Evaluation for XGBoost\n",
      "Average Test MAE: 14988.47906511671, Best Test MAE: 14366.55820107268\n",
      "Average Test MSE: 429124013.7419244, Best Test MSE: 406312497.5203679\n",
      "Average Test RMSE: 20713.149097035737, Best Test RMSE: 20157.19468379387\n",
      "Average Test R2: 0.36637578343984356, Best Test R2: 0.40005818906519186\n",
      "Average Test MAPE: 21.22509149611409, Best Test MAPE: 19.900772261978776\n",
      "Average Test MALE: 0.23436218692116118, Best Test MALE: 0.2201400285523563\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "test_male_list = {} \n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [200,400,1000], 'learning_rate': [0.05]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0),\n",
    "        'params': {'depth': [ 8, 10], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor( learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "    test_male_list[name] = [] \n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "        test_male = mean_absolute_error(np.log1p(y_test), np.log1p(y_pred_test)) \n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "        test_male_list[name].append(test_male)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "    avg_test_male = np.mean(test_male_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "    best_test_male = np.min(test_male_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(f\"Average Test MALE: {avg_test_male}, Best Test MALE: {best_test_male}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = embedded_train,embedded_test,dataset.y_train,dataset.y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Original feature names\n",
    "\n",
    "# Initialize the Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation for Linear Regression\n",
      "Average Test MAE: 4772.366677019483, Best Test MAE: 4746.529726494089\n",
      "Average Test MSE: 61630708.495675005, Best Test MSE: 61285168.143553704\n",
      "Average Test RMSE: 7850.502425308563, Best Test RMSE: 7828.4844091020395\n",
      "Average Test R2: 0.9089990116234684, Best Test R2: 0.909509220159676\n",
      "Average Test MAPE: 7.624320321845824, Best Test MAPE: 7.568865503848032\n",
      "Average Test MALE: 0.07395975804263254, Best Test MALE: 0.07347002106812871\n",
      "\n",
      "\n",
      "Test Set Evaluation for KNN\n",
      "Average Test MAE: 4880.169730735552, Best Test MAE: 4872.636449211909\n",
      "Average Test MSE: 62981984.65811026, Best Test MSE: 62799840.62786263\n",
      "Average Test RMSE: 7936.114912881063, Best Test RMSE: 7924.635046982456\n",
      "Average Test R2: 0.9070037811717547, Best Test R2: 0.907272726429468\n",
      "Average Test MAPE: 7.776341090362996, Best Test MAPE: 7.7635892042766\n",
      "Average Test MALE: 0.07536436584161497, Best Test MALE: 0.07525315914303446\n",
      "\n",
      "\n",
      "Test Set Evaluation for Decision Tree\n",
      "Average Test MAE: 4893.081338679523, Best Test MAE: 4858.315874141309\n",
      "Average Test MSE: 63230613.95433428, Best Test MSE: 62395775.42980879\n",
      "Average Test RMSE: 7951.72999783413, Best Test RMSE: 7899.099659442764\n",
      "Average Test R2: 0.9066366669157612, Best Test R2: 0.9078693499843318\n",
      "Average Test MAPE: 7.851515534561019, Best Test MAPE: 7.807717004940411\n",
      "Average Test MALE: 0.07598679967292715, Best Test MALE: 0.07557981658442332\n",
      "\n",
      "\n",
      "Test Set Evaluation for Random Forest\n",
      "Average Test MAE: 4800.895532315104, Best Test MAE: 4790.6069267903185\n",
      "Average Test MSE: 61987850.70887905, Best Test MSE: 61695189.7870506\n",
      "Average Test RMSE: 7873.228600224286, Best Test RMSE: 7854.628558184696\n",
      "Average Test R2: 0.9084716723280776, Best Test R2: 0.9089038015992743\n",
      "Average Test MAPE: 7.656206745096337, Best Test MAPE: 7.64030074575235\n",
      "Average Test MALE: 0.074198062964384, Best Test MALE: 0.07405768728168231\n",
      "\n",
      "\n",
      "Test Set Evaluation for SVM\n",
      "Average Test MAE: 5082.231415439686, Best Test MAE: 5076.079483708119\n",
      "Average Test MSE: 71456222.20973325, Best Test MSE: 71226891.57230258\n",
      "Average Test RMSE: 8453.175183036734, Best Test RMSE: 8439.602571940375\n",
      "Average Test R2: 0.8944911229246193, Best Test R2: 0.8948297416940705\n",
      "Average Test MAPE: 8.113501515266092, Best Test MAPE: 8.108376353890698\n",
      "Average Test MALE: 0.07820976649839195, Best Test MALE: 0.0781554995871541\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66004.307404\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65998.368214\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65993.494308\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65978.805410\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66037.512843\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66010.269654\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66066.609408\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65986.819761\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65989.987400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8415\n",
      "[LightGBM] [Info] Number of data points in the train set: 20556, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65928.604933\n",
      "Test Set Evaluation for LightGBM\n",
      "Average Test MAE: 4810.3394120426265, Best Test MAE: 4798.789369702532\n",
      "Average Test MSE: 62266316.57301501, Best Test MSE: 61915143.72594815\n",
      "Average Test RMSE: 7890.89363780687, Best Test RMSE: 7868.617650257773\n",
      "Average Test R2: 0.9080605028074924, Best Test R2: 0.9085790280192595\n",
      "Average Test MAPE: 7.676692922502589, Best Test MAPE: 7.662987892151377\n",
      "Average Test MALE: 0.07427653979205873, Best Test MALE: 0.07415031952480913\n",
      "\n",
      "\n",
      "Test Set Evaluation for CatBoost\n",
      "Average Test MAE: 4768.890505381065, Best Test MAE: 4760.416079373112\n",
      "Average Test MSE: 61755066.64058161, Best Test MSE: 61632252.5626395\n",
      "Average Test RMSE: 7858.435051974256, Best Test RMSE: 7850.621157758123\n",
      "Average Test R2: 0.9088153902701626, Best Test R2: 0.9089967317272394\n",
      "Average Test MAPE: 7.604426096866352, Best Test MAPE: 7.5910791152237564\n",
      "Average Test MALE: 0.07365131258962672, Best Test MALE: 0.07351494250756091\n",
      "\n",
      "\n",
      "Test Set Evaluation for XGBoost\n",
      "Average Test MAE: 4785.268372578262, Best Test MAE: 4773.070679865368\n",
      "Average Test MSE: 61836277.26278897, Best Test MSE: 61537848.170568995\n",
      "Average Test RMSE: 7863.596537750951, Best Test RMSE: 7844.606310744281\n",
      "Average Test R2: 0.9086954785075376, Best Test R2: 0.9091361247862386\n",
      "Average Test MAPE: 7.634826903305918, Best Test MAPE: 7.615135021491187\n",
      "Average Test MALE: 0.07396105099217902, Best Test MALE: 0.07378320912844667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "test_male_list = {} \n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 40]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 40]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [100,200,400], 'learning_rate': [0.05, 0.1]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0),\n",
    "        'params': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05],'n_estimators': [100,200,400,800]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor( learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.01, 0.05, 0.1],'n_estimators': [100,200,400,800]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "    test_male_list[name] = [] \n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "        test_male = mean_absolute_error(np.log1p(y_test), np.log1p(y_pred_test)) \n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "        test_male_list[name].append(test_male)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "    avg_test_male = np.mean(test_male_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "    best_test_male = np.min(test_male_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(f\"Average Test MALE: {avg_test_male}, Best Test MALE: {best_test_male}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MODEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
