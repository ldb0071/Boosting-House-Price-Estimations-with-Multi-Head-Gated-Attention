{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training attention based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train_model import train\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8, 4)\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['axes.facecolor'] = '#ffffff'\n",
    "rcParams['lines.linewidth'] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the file: D:\\Final_file\\ASI-main\\output\\models\\IT\\asi_IT_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = r\"D:\\Final_file\\ASI-main\\output\\models\\IT\\asi_IT_weights.hdf5\"\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed the file: {file_path}\")\n",
    "else:\n",
    "    print(f\"The file {file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BEST IT\n",
    "\n",
    "hyperparameter={\n",
    "\"num_nearest\":40,\n",
    "\"sigma\":2,\n",
    "\"geointerpolation\": 'asi_multi',\n",
    "'type_compat_funct_eucli':'identity',\n",
    "'Num_heads':8,\n",
    "\"learning_rate\":0.001,\n",
    "\"batch_size\":32,\n",
    "\"num_neuron\":60,\n",
    "\"num_layers\":5,\n",
    "\"size_embedded\":50,\n",
    "\"num_nearest_geo\":30,\n",
    "\"num_nearest_eucli\":25,\n",
    "\"id_dataset\":'IT',\n",
    "\"epochs\":300,\n",
    "\"optimier\":'adam',\n",
    "\"validation_split\":0.1,\n",
    "\"label\":'asi_IT',\n",
    "\"early_stopping\": False,\n",
    "'scale_log':False,\n",
    "\"graph_label\":'matrix',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = train(**hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,\\\n",
    "result,\\\n",
    "fit,\\\n",
    "embedded_train,\\\n",
    "embedded_test,\\\n",
    "predict_regression_train,\\\n",
    "predict_regression_test = spatial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Test ##########################\n",
      "MALE test:.... 0.13318920943380927\n",
      "RMSE test:.... 46473.58619153165\n",
      "MAPE test:.... 13.980159078004906\n",
      "################# Train ##########################\n",
      "MALE train:.... 0.13318920943380927\n",
      "RMSE train:.... 44279.78419996523\n",
      "MAPE train:.... 12.575263850756183\n"
     ]
    }
   ],
   "source": [
    "#asi\n",
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Test ##########################\n",
      "MALE test:.... 0.13128807562459377\n",
      "RMSE test:.... 45797.649009432156\n",
      "MAPE test:.... 13.779126627211536\n",
      "################# Train ##########################\n",
      "MALE train:.... 0.13128807562459377\n",
      "RMSE train:.... 44220.15179854315\n",
      "MAPE train:.... 12.734757197189131\n"
     ]
    }
   ],
   "source": [
    "#asi_multi\n",
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\Final_file\\ASI-main\\datasets\\IT\\data.npz'\n",
    "data = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the mean absolute percentage error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def mean_absolute_log_error(y_true, y_pred):\n",
    "    # Ensure all values are positive with a small constant (e.g., 1e-10)\n",
    "    y_true_pos = np.maximum(y_true, 1e-10) + 1\n",
    "    y_pred_pos = np.maximum(y_pred, 1e-10) + 1\n",
    "    y_true_log = np.log(y_true_pos)\n",
    "    y_pred_log = np.log(y_pred_pos)\n",
    "    return mean_absolute_error(y_true_log, y_pred_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models benchmarking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation for Linear Regression\n",
      "Average Test MAE: 58093.08058097004, Best Test MAE: 58064.76742870805\n",
      "Average Test MSE: 5812678571.317408, Best Test MSE: 5810110355.881016\n",
      "Average Test RMSE: 76240.92357961097, Best Test RMSE: 76224.07989527336\n",
      "Average Test R2: 0.7422545297611219, Best Test R2: 0.7423684094273045\n",
      "Average Test MAPE: 29.400632407979543, Best Test MAPE: 29.352031314845984\n",
      "Average Test MALE: 0.3886035663677529, Best Test MALE: 0.38527007344245323\n",
      "\n",
      "\n",
      "Test Set Evaluation for KNN\n",
      "Average Test MAE: 61266.84217335058, Best Test MAE: 60793.735640362225\n",
      "Average Test MSE: 7252818072.698311, Best Test MSE: 7163435942.79412\n",
      "Average Test RMSE: 85163.21845646147, Best Test RMSE: 84637.08373280663\n",
      "Average Test R2: 0.6783959440095145, Best Test R2: 0.6823593214473773\n",
      "Average Test MAPE: 27.96700025082716, Best Test MAPE: 27.73906339881466\n",
      "Average Test MALE: 0.24898910298269414, Best Test MALE: 0.24736744501670985\n",
      "\n",
      "\n",
      "Test Set Evaluation for Decision Tree\n",
      "Average Test MAE: 50538.04772781026, Best Test MAE: 48275.19270064104\n",
      "Average Test MSE: 4960027002.527048, Best Test MSE: 4772741952.527111\n",
      "Average Test RMSE: 70423.17751310984, Best Test RMSE: 69085.0342152851\n",
      "Average Test R2: 0.7800627582484543, Best Test R2: 0.7883673415294122\n",
      "Average Test MAPE: 22.341616606642123, Best Test MAPE: 21.087646846272058\n",
      "Average Test MALE: 0.20549456695999813, Best Test MALE: 0.1970276667767529\n",
      "\n",
      "\n",
      "Test Set Evaluation for Random Forest\n",
      "Average Test MAE: 36261.49366332414, Best Test MAE: 36170.23484779861\n",
      "Average Test MSE: 2719389039.130128, Best Test MSE: 2680549435.7385793\n",
      "Average Test RMSE: 52147.441350369496, Best Test RMSE: 51774.02278883281\n",
      "Average Test R2: 0.8794170023245946, Best Test R2: 0.8811392258601337\n",
      "Average Test MAPE: 16.309763719168444, Best Test MAPE: 16.24349661638127\n",
      "Average Test MALE: 0.1508981315293439, Best Test MALE: 0.15020188689534988\n",
      "\n",
      "\n",
      "Test Set Evaluation for SVM\n",
      "Average Test MAE: 96562.2274141196, Best Test MAE: 96510.91103458898\n",
      "Average Test MSE: 16584538051.057896, Best Test MSE: 16546629979.317497\n",
      "Average Test RMSE: 128780.94558563604, Best Test RMSE: 128633.70467850757\n",
      "Average Test R2: 0.264609335228445, Best Test R2: 0.26629025283926744\n",
      "Average Test MAPE: 50.908266311293325, Best Test MAPE: 50.77313607036624\n",
      "Average Test MALE: 0.4074795396771017, Best Test MALE: 0.4072512767387201\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2352\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268870.836703\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2352\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268260.339218\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2352\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268509.675157\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2350\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268689.178661\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2355\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268933.588832\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2357\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268491.994789\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2351\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 269027.602534\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2354\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 269176.175733\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2356\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268831.805759\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2357\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 268918.087103\n",
      "Test Set Evaluation for LightGBM\n",
      "Average Test MAE: 32811.09357956521, Best Test MAE: 32664.868321131362\n",
      "Average Test MSE: 2161510989.8480406, Best Test MSE: 2132888517.4425461\n",
      "Average Test RMSE: 46491.82859501226, Best Test RMSE: 46183.20601087094\n",
      "Average Test R2: 0.9041543997884235, Best Test R2: 0.9054235758694745\n",
      "Average Test MAPE: 14.629384858737364, Best Test MAPE: 14.577560641699321\n",
      "Average Test MALE: 0.13847724107786802, Best Test MALE: 0.13813475532679584\n",
      "\n",
      "\n",
      "Test Set Evaluation for CatBoost\n",
      "Average Test MAE: 32364.838153871948, Best Test MAE: 32192.301366723765\n",
      "Average Test MSE: 2137481386.9968464, Best Test MSE: 2110627717.8110626\n",
      "Average Test RMSE: 46232.5906512327, Best Test RMSE: 45941.56851709639\n",
      "Average Test R2: 0.9052199191028917, Best Test R2: 0.9064106630098545\n",
      "Average Test MAPE: 14.510328317279496, Best Test MAPE: 14.449057060706302\n",
      "Average Test MALE: 0.13684259764610024, Best Test MALE: 0.13626996801338304\n",
      "\n",
      "\n",
      "Test Set Evaluation for XGBoost\n",
      "Average Test MAE: 32314.032232673908, Best Test MAE: 32092.618787521224\n",
      "Average Test MSE: 2152594240.329926, Best Test MSE: 2116768859.2436981\n",
      "Average Test RMSE: 46395.655674001246, Best Test RMSE: 46008.35640667571\n",
      "Average Test R2: 0.9045497858001135, Best Test R2: 0.9061383528576695\n",
      "Average Test MAPE: 14.343523076149058, Best Test MAPE: 14.252619320922244\n",
      "Average Test MALE: 0.1358732663122365, Best Test MALE: 0.1350713577614074\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "test_male_list = {} \n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [200,400,1000], 'learning_rate': [0.05]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0),\n",
    "        'params': {'depth': [ 8, 10], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor( learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "    test_male_list[name] = [] \n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "        test_male = mean_absolute_log_error((y_test), (y_pred_test)) \n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "        test_male_list[name].append(test_male)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "    avg_test_male = np.mean(test_male_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "    best_test_male = np.min(test_male_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(f\"Average Test MALE: {avg_test_male}, Best Test MALE: {best_test_male}\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = embedded_train,embedded_test,dataset.y_train,dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation for Linear Regression\n",
      "Average Test MAE: 31180.073168155726, Best Test MAE: 31158.668807608345\n",
      "Average Test MSE: 2103890502.852539, Best Test MSE: 2101100031.6004324\n",
      "Average Test RMSE: 45868.18264631477, Best Test RMSE: 45837.757706943215\n",
      "Average Test R2: 0.9067094042212048, Best Test R2: 0.9068331391424185\n",
      "Average Test MAPE: 13.980914104332777, Best Test MAPE: 13.944543179821991\n",
      "Average Test MALE: 0.13189330401560767, Best Test MALE: 0.13176323722085304\n",
      "\n",
      "\n",
      "Test Set Evaluation for KNN\n",
      "Average Test MAE: 32219.40468709573, Best Test MAE: 32141.967795924968\n",
      "Average Test MSE: 2186569268.0298276, Best Test MSE: 2176044445.331173\n",
      "Average Test RMSE: 46760.704931323606, Best Test RMSE: 46648.091550793084\n",
      "Average Test R2: 0.9030432670096026, Best Test R2: 0.9035099581129145\n",
      "Average Test MAPE: 14.350143294479162, Best Test MAPE: 14.324406347290578\n",
      "Average Test MALE: 0.13544054767885055, Best Test MALE: 0.13520619193407202\n",
      "\n",
      "\n",
      "Test Set Evaluation for Decision Tree\n",
      "Average Test MAE: 31689.082361534907, Best Test MAE: 31602.09319598437\n",
      "Average Test MSE: 2130787719.411749, Best Test MSE: 2116658942.5163233\n",
      "Average Test RMSE: 46160.315359816464, Best Test RMSE: 46007.16186113118\n",
      "Average Test R2: 0.9055167293390293, Best Test R2: 0.9061432267790874\n",
      "Average Test MAPE: 14.366802226951716, Best Test MAPE: 14.322706451772223\n",
      "Average Test MALE: 0.1350547415397516, Best Test MALE: 0.1347016558674706\n",
      "\n",
      "\n",
      "Test Set Evaluation for Random Forest\n",
      "Average Test MAE: 31432.851205287407, Best Test MAE: 31383.48935275906\n",
      "Average Test MSE: 2115580051.0193367, Best Test MSE: 2108710560.9877806\n",
      "Average Test RMSE: 45995.40482995696, Best Test RMSE: 45920.698611713\n",
      "Average Test R2: 0.9061910669259003, Best Test R2: 0.9064956734711893\n",
      "Average Test MAPE: 14.049031253941234, Best Test MAPE: 14.033771267580708\n",
      "Average Test MALE: 0.1325380741971609, Best Test MALE: 0.13235914361268658\n",
      "\n",
      "\n",
      "Test Set Evaluation for SVM\n",
      "Average Test MAE: 39746.368685910595, Best Test MAE: 39655.932692931\n",
      "Average Test MSE: 3503223025.114502, Best Test MSE: 3478290215.1320477\n",
      "Average Test RMSE: 59187.872386077, Best Test RMSE: 58977.031250581334\n",
      "Average Test R2: 0.8446602792703268, Best Test R2: 0.8457658485452244\n",
      "Average Test MAPE: 20.009552521241794, Best Test MAPE: 19.98630102243755\n",
      "Average Test MALE: 0.17453748238653816, Best Test MALE: 0.17435500847158472\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268870.836703\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268260.339218\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268509.675157\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22260, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268689.178661\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268933.588832\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268491.994789\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 269027.602534\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 269176.175733\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268831.805759\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 22261, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 268918.087103\n",
      "Test Set Evaluation for LightGBM\n",
      "Average Test MAE: 31421.93824817179, Best Test MAE: 31347.9161568019\n",
      "Average Test MSE: 2109638541.9301841, Best Test MSE: 2105447070.8244386\n",
      "Average Test RMSE: 45930.79023563652, Best Test RMSE: 45885.150875031875\n",
      "Average Test R2: 0.9064545249918028, Best Test R2: 0.9066403829706826\n",
      "Average Test MAPE: 14.071941596336643, Best Test MAPE: 14.045244645356696\n",
      "Average Test MALE: 0.13267101045318538, Best Test MALE: 0.13242759285963532\n",
      "\n",
      "\n",
      "Test Set Evaluation for CatBoost\n",
      "Average Test MAE: 31241.04356365286, Best Test MAE: 31206.844593210466\n",
      "Average Test MSE: 2093276981.9939399, Best Test MSE: 2089247829.8261921\n",
      "Average Test RMSE: 45752.3362522767, Best Test RMSE: 45708.290602758185\n",
      "Average Test R2: 0.9071800283733967, Best Test R2: 0.9073586888149466\n",
      "Average Test MAPE: 14.01409661568313, Best Test MAPE: 13.99487105830801\n",
      "Average Test MALE: 0.1321320053607986, Best Test MALE: 0.13202189048284568\n",
      "\n",
      "\n",
      "Test Set Evaluation for XGBoost\n",
      "Average Test MAE: 31415.146288809832, Best Test MAE: 31386.06293079924\n",
      "Average Test MSE: 2117985547.859386, Best Test MSE: 2112465559.0527256\n",
      "Average Test RMSE: 46021.559870826706, Best Test RMSE: 45961.56610748513\n",
      "Average Test R2: 0.9060844025186757, Best Test R2: 0.9063291695556329\n",
      "Average Test MAPE: 14.060874559183366, Best Test MAPE: 14.0442945508347\n",
      "Average Test MALE: 0.13250407317556523, Best Test MALE: 0.13239303433087246\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "test_male_list = {} \n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [200,400,1000], 'learning_rate': [0.05]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0),\n",
    "        'params': {'depth': [ 8, 10], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor( learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "    test_male_list[name] = [] \n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "        test_male = mean_absolute_error(np.log1p(y_test), np.log1p(y_pred_test)) \n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "        test_male_list[name].append(test_male)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "    avg_test_male = np.mean(test_male_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "    best_test_male = np.min(test_male_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(f\"Average Test MALE: {avg_test_male}, Best Test MALE: {best_test_male}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MODEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
