{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training attention based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the file: D:\\Final_file\\ASI-main\\output\\models\\kc\\asi_kc_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = r\"D:\\Final_file\\ASI-main\\output\\models\\kc\\asi_kc_weights.hdf5\"\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "# Check if the file exists and remove it\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed the file: {file_path}\")\n",
    "else:\n",
    "    print(f\"The file {file_path} does not exist\")\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train_model import train\n",
    "import tensorflow as tf\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8, 4)\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['axes.facecolor'] = '#ffffff'\n",
    "rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "\n",
    "hyperparameter={\n",
    "\"num_nearest\":60,\n",
    "\"sigma\":2,\n",
    "'type_compat_funct_eucli':'kernel_gaussiano',\n",
    "\"geointerpolation\": 'asi_multi',\n",
    "'Num_heads':8,\n",
    "\"learning_rate\":0.001,\n",
    "\"batch_size\":250,\n",
    "\"num_neuron\":60,\n",
    "\"num_layers\":3,\n",
    "\"size_embedded\":50,\n",
    "\"num_nearest_geo\":30,\n",
    "\"num_nearest_eucli\":30,\n",
    "\"id_dataset\":'kc',\n",
    "\"epochs\":300,\n",
    "\"optimier\":'adam',\n",
    "\"validation_split\":0.1,\n",
    "\"label\":'asi_kc',\n",
    "\"early_stopping\": False,\n",
    "'scale_log':True,\n",
    "\"graph_label\":'matrix',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0916 - root_mean_squared_error: 0.1347 - val_loss: 0.1214 - val_root_mean_squared_error: 0.1742\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.11113\n",
      "Epoch 250/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0933 - root_mean_squared_error: 0.1353 - val_loss: 0.1209 - val_root_mean_squared_error: 0.1734\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.11113\n",
      "Epoch 251/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0926 - root_mean_squared_error: 0.1352 - val_loss: 0.1238 - val_root_mean_squared_error: 0.1745\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.11113\n",
      "Epoch 252/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0914 - root_mean_squared_error: 0.1343 - val_loss: 0.1202 - val_root_mean_squared_error: 0.1711\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.11113\n",
      "Epoch 253/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0914 - root_mean_squared_error: 0.1344 - val_loss: 0.1227 - val_root_mean_squared_error: 0.1744\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.11113\n",
      "Epoch 254/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0930 - root_mean_squared_error: 0.1357 - val_loss: 0.1194 - val_root_mean_squared_error: 0.1704\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.11113\n",
      "Epoch 255/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0908 - root_mean_squared_error: 0.1334 - val_loss: 0.1221 - val_root_mean_squared_error: 0.1740\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.11113\n",
      "Epoch 256/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0924 - root_mean_squared_error: 0.1352 - val_loss: 0.1212 - val_root_mean_squared_error: 0.1714\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.11113\n",
      "Epoch 257/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0907 - root_mean_squared_error: 0.1340 - val_loss: 0.1201 - val_root_mean_squared_error: 0.1715\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.11113\n",
      "Epoch 258/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0905 - root_mean_squared_error: 0.1333 - val_loss: 0.1240 - val_root_mean_squared_error: 0.1762\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.11113\n",
      "Epoch 259/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0935 - root_mean_squared_error: 0.1361 - val_loss: 0.1225 - val_root_mean_squared_error: 0.1727\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.11113\n",
      "Epoch 260/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0935 - root_mean_squared_error: 0.1359 - val_loss: 0.1246 - val_root_mean_squared_error: 0.1775\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.11113\n",
      "Epoch 261/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0935 - root_mean_squared_error: 0.1354 - val_loss: 0.1225 - val_root_mean_squared_error: 0.1724\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.11113\n",
      "Epoch 262/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0912 - root_mean_squared_error: 0.1339 - val_loss: 0.1249 - val_root_mean_squared_error: 0.1770\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.11113\n",
      "Epoch 263/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0906 - root_mean_squared_error: 0.1332 - val_loss: 0.1205 - val_root_mean_squared_error: 0.1710\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.11113\n",
      "Epoch 264/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0887 - root_mean_squared_error: 0.1316 - val_loss: 0.1352 - val_root_mean_squared_error: 0.1861\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.11113\n",
      "Epoch 265/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0914 - root_mean_squared_error: 0.1341 - val_loss: 0.1287 - val_root_mean_squared_error: 0.1778\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.11113\n",
      "Epoch 266/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0900 - root_mean_squared_error: 0.1326 - val_loss: 0.1206 - val_root_mean_squared_error: 0.1723\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.11113\n",
      "Epoch 267/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0896 - root_mean_squared_error: 0.1323 - val_loss: 0.1250 - val_root_mean_squared_error: 0.1766\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.11113\n",
      "Epoch 268/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0915 - root_mean_squared_error: 0.1340 - val_loss: 0.1238 - val_root_mean_squared_error: 0.1747\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.11113\n",
      "Epoch 269/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0909 - root_mean_squared_error: 0.1335 - val_loss: 0.1212 - val_root_mean_squared_error: 0.1730\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.11113\n",
      "Epoch 270/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0898 - root_mean_squared_error: 0.1325 - val_loss: 0.1234 - val_root_mean_squared_error: 0.1754\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.11113\n",
      "Epoch 271/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0887 - root_mean_squared_error: 0.1317 - val_loss: 0.1215 - val_root_mean_squared_error: 0.1752\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.11113\n",
      "Epoch 272/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0897 - root_mean_squared_error: 0.1324 - val_loss: 0.1307 - val_root_mean_squared_error: 0.1838\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.11113\n",
      "Epoch 273/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0893 - root_mean_squared_error: 0.1322 - val_loss: 0.1241 - val_root_mean_squared_error: 0.1759\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.11113\n",
      "Epoch 274/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0894 - root_mean_squared_error: 0.1321 - val_loss: 0.1223 - val_root_mean_squared_error: 0.1740\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.11113\n",
      "Epoch 275/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0912 - root_mean_squared_error: 0.1337 - val_loss: 0.1304 - val_root_mean_squared_error: 0.1825\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.11113\n",
      "Epoch 276/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0896 - root_mean_squared_error: 0.1323 - val_loss: 0.1234 - val_root_mean_squared_error: 0.1752\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.11113\n",
      "Epoch 277/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0883 - root_mean_squared_error: 0.1309 - val_loss: 0.1244 - val_root_mean_squared_error: 0.1762\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.11113\n",
      "Epoch 278/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0905 - root_mean_squared_error: 0.1331 - val_loss: 0.1254 - val_root_mean_squared_error: 0.1765\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.11113\n",
      "Epoch 279/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0911 - root_mean_squared_error: 0.1332 - val_loss: 0.1218 - val_root_mean_squared_error: 0.1733\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.11113\n",
      "Epoch 280/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0882 - root_mean_squared_error: 0.1314 - val_loss: 0.1225 - val_root_mean_squared_error: 0.1752\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.11113\n",
      "Epoch 281/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0881 - root_mean_squared_error: 0.1307 - val_loss: 0.1227 - val_root_mean_squared_error: 0.1763\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.11113\n",
      "Epoch 282/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0876 - root_mean_squared_error: 0.1303 - val_loss: 0.1226 - val_root_mean_squared_error: 0.1736\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.11113\n",
      "Epoch 283/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0885 - root_mean_squared_error: 0.1307 - val_loss: 0.1277 - val_root_mean_squared_error: 0.1803\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.11113\n",
      "Epoch 284/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0883 - root_mean_squared_error: 0.1306 - val_loss: 0.1245 - val_root_mean_squared_error: 0.1750\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.11113\n",
      "Epoch 285/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0893 - root_mean_squared_error: 0.1314 - val_loss: 0.1244 - val_root_mean_squared_error: 0.1760\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.11113\n",
      "Epoch 286/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0874 - root_mean_squared_error: 0.1297 - val_loss: 0.1344 - val_root_mean_squared_error: 0.1862\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.11113\n",
      "Epoch 287/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0888 - root_mean_squared_error: 0.1311 - val_loss: 0.1255 - val_root_mean_squared_error: 0.1782\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.11113\n",
      "Epoch 288/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0874 - root_mean_squared_error: 0.1297 - val_loss: 0.1239 - val_root_mean_squared_error: 0.1774\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.11113\n",
      "Epoch 289/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0877 - root_mean_squared_error: 0.1303 - val_loss: 0.1224 - val_root_mean_squared_error: 0.1739\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.11113\n",
      "Epoch 290/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0871 - root_mean_squared_error: 0.1296 - val_loss: 0.1259 - val_root_mean_squared_error: 0.1787\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.11113\n",
      "Epoch 291/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0883 - root_mean_squared_error: 0.1303 - val_loss: 0.1240 - val_root_mean_squared_error: 0.1766\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.11113\n",
      "Epoch 292/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0862 - root_mean_squared_error: 0.1278 - val_loss: 0.1257 - val_root_mean_squared_error: 0.1782\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.11113\n",
      "Epoch 293/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0873 - root_mean_squared_error: 0.1296 - val_loss: 0.1241 - val_root_mean_squared_error: 0.1774\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.11113\n",
      "Epoch 294/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0890 - root_mean_squared_error: 0.1306 - val_loss: 0.1241 - val_root_mean_squared_error: 0.1757\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.11113\n",
      "Epoch 295/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0875 - root_mean_squared_error: 0.1298 - val_loss: 0.1250 - val_root_mean_squared_error: 0.1780\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.11113\n",
      "Epoch 296/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0856 - root_mean_squared_error: 0.1280 - val_loss: 0.1279 - val_root_mean_squared_error: 0.1816\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.11113\n",
      "Epoch 297/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0865 - root_mean_squared_error: 0.1289 - val_loss: 0.1286 - val_root_mean_squared_error: 0.1815\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.11113\n",
      "Epoch 298/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0864 - root_mean_squared_error: 0.1286 - val_loss: 0.1285 - val_root_mean_squared_error: 0.1804\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.11113\n",
      "Epoch 299/300\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0867 - root_mean_squared_error: 0.1286 - val_loss: 0.1250 - val_root_mean_squared_error: 0.1779\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.11113\n",
      "Epoch 300/300\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0872 - root_mean_squared_error: 0.1291 - val_loss: 0.1270 - val_root_mean_squared_error: 0.1801\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.11113\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "                spatial = train(**hyperparameter)\n",
    "\n",
    "\n",
    "\n",
    "dataset,\\\n",
    "result,\\\n",
    "fit,\\\n",
    "embedded_train,\\\n",
    "embedded_test,\\\n",
    "predict_regression_train,\\\n",
    "predict_regression_test = spatial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Test ##########################\n",
      "MALE test:.... 59832.56919901087\n",
      "RMSE test:.... 106718.14164977851\n",
      "MAPE test:.... 7.81711682177995\n",
      "################# Train ##########################\n",
      "MALE train:.... 59832.56919901087\n",
      "RMSE train:.... 95447.14931026251\n",
      "MAPE train:.... 7.088837274698526\n"
     ]
    }
   ],
   "source": [
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models benchmarking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = dataset.X_train,dataset.X_test,dataset.y_train,dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation for Linear Regression\n",
      "Average Test MAE: 81020426.98264065, Best Test MAE: 6763098.845050364\n",
      "Average Test MSE: 1.655068454400296e+16, Best Test MSE: 74197681284552.64\n",
      "Average Test RMSE: 103191508.16920346, Best Test RMSE: 8613807.595050672\n",
      "Average Test R2: -6.050596421595358e+16, Best Test R2: -271251756190142.75\n",
      "Average Test MAPE: 614187842.8460655, Best Test MAPE: 51268713.90464589\n",
      "\n",
      "\n",
      "Test Set Evaluation for KNN\n",
      "Average Test MAE: 0.15101256533249896, Best Test MAE: 0.14991162720726087\n",
      "Average Test MSE: 0.04409406166628952, Best Test MSE: 0.04380281939509842\n",
      "Average Test RMSE: 0.20998546824682113, Best Test RMSE: 0.20929123105161004\n",
      "Average Test R2: 0.8388010048633738, Best Test R2: 0.8398657278596955\n",
      "Average Test MAPE: 1.1577480090337369, Best Test MAPE: 1.149350053838588\n",
      "\n",
      "\n",
      "Test Set Evaluation for Decision Tree\n",
      "Average Test MAE: 0.16255267634496678, Best Test MAE: 0.15995405086206627\n",
      "Average Test MSE: 0.05036125912416818, Best Test MSE: 0.04863046642289661\n",
      "Average Test RMSE: 0.22440077467355266, Best Test RMSE: 0.22052316527498106\n",
      "Average Test R2: 0.8158893951282875, Best Test R2: 0.8222168241219311\n",
      "Average Test MAPE: 1.2458992971105358, Best Test MAPE: 1.2270760369795366\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8178375f6ab1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Grid Search for hyperparameter tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the mean absolute percentage error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "\n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [1, 10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [1000, 2000], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0, n_estimators=2000),\n",
    "        'params': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train ,X_test, y_train , y_test = embedded_train,embedded_test,dataset.y_train,dataset.y_test\n",
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "\n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [1, 10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [1000], 'learning_rate': [0.05, 0.1]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0, n_estimators=2000),\n",
    "        'params': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(n_estimators=2000, learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to embedded_train and embedded_test to reduce embeddings to 12 dimensions\n",
    "pca = PCA(n_components=6)\n",
    "embedded_train_pca = pca.fit_transform(embedded_train)\n",
    "embedded_test_pca = pca.transform(embedded_test)\n",
    "\n",
    "# Concatenate dataset.X_train with embedded_train_pca and dataset.X_test with embedded_test_pca\n",
    "X_train_concat = np.concatenate((dataset.X_train, embedded_train_pca), axis=1)\n",
    "X_test_concat = np.concatenate((dataset.X_test, embedded_test_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = X_train_concat,X_test_concat,dataset.y_train,dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation for Linear Regression\n",
      "Average Test MAE: 5050539671.819971, Best Test MAE: 0.12642510337124008\n",
      "Average Test MSE: 8.338774470854936e+19, Best Test MSE: 0.030241018794338197\n",
      "Average Test RMSE: 6432609962.995263, Best Test RMSE: 0.1738994502416215\n",
      "Average Test R2: -3.048487743192925e+20, Best Test R2: 0.8894449352738579\n",
      "Average Test MAPE: 38286394946.88451, Best Test MAPE: 0.9736746829483642\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-01d6679aa336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Make predictions on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# Evaluate the model on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 **kwds))\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kd_tree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1623\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[1;32m-> 1624\u001b[1;33m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[0;32m   1625\u001b[0m         if ((X is Y or Y is None)\n\u001b[0;32m   1626\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "\n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [1, 10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [1000], 'learning_rate': [0.05, 0.1]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0, n_estimators=2000),\n",
    "        'params': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(n_estimators=2000, learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MODEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
