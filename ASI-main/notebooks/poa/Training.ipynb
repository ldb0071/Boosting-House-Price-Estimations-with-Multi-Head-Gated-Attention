{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training attention based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import tensorflow as tf\n",
    "from train_model import train\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8, 4)\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['axes.facecolor'] = '#ffffff'\n",
    "rcParams['lines.linewidth'] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file D:\\Final_file\\ASI-main\\output\\models\\poa\\asi_poa_weights.hdf5 does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = r\"D:\\Final_file\\ASI-main\\output\\models\\poa\\asi_poa_weights.hdf5\"\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed the file: {file_path}\")\n",
    "else:\n",
    "    print(f\"The file {file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BEST POA\n",
    "\n",
    "hyperparameter={\n",
    "\"num_nearest\":60,\n",
    "\"sigma\":10,\n",
    "\"geointerpolation\": 'asi_multi',\n",
    "'type_compat_funct_eucli':'identity',\n",
    "'Num_heads':4,\n",
    "\"learning_rate\":0.001,\n",
    "\"batch_size\":32,\n",
    "\"num_neuron\":60,\n",
    "\"num_layers\":3,\n",
    "\"size_embedded\":50,\n",
    "\"num_nearest_geo\":10,\n",
    "\"num_nearest_eucli\":15,\n",
    "\"id_dataset\":'poa',\n",
    "\"epochs\":200,\n",
    "\"optimier\":'adam',\n",
    "\"validation_split\":0.1,\n",
    "\"label\":'asi_poa',\n",
    "\"early_stopping\": False,\n",
    "'scale_log':True,\n",
    "\"graph_label\":'matrix',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = train(**hyperparameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/200\n",
      "346/346 [==============================] - 3s 6ms/step - loss: 1.2933 - root_mean_squared_error: 3.1581 - val_loss: 0.2413 - val_root_mean_squared_error: 0.3085\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24127, saving model to d:\\Final_file\\ASI-main/output/models/poa\\asi_poa_weights.hdf5\n",
      "Epoch 2/200\n",
      "258/346 [=====================>........] - ETA: 0s - loss: 0.2243 - root_mean_squared_error: 0.2874"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d19266bfdb23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0membedded_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpredict_regression_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpredict_regression_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspatial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Final_file\\ASI-main\\train_model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                                     \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                                     \u001b[0mnum_nearest_geo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNUM_NEAREST_GEO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                                     num_nearest_eucli=self.NUM_NEAREST_EUCLI)\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Final_file\\ASI-main\\asi\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model, num_nearest_geo, num_nearest_eucli, epochs, batch_size, validation_split, label)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             fit = model.fit(train_features, [train_y], epochs=epochs, batch_size=batch_size,\n\u001b[1;32m--> 327\u001b[1;33m                             validation_data=(val_features, [val_y]), verbose=1, callbacks=[ud.history, checkpoint],shuffle=True)\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\zabde\\anaconda3\\envs\\MODEL\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset,\\\n",
    "result,\\\n",
    "fit,\\\n",
    "embedded_train,\\\n",
    "embedded_test,\\\n",
    "predict_regression_train,\\\n",
    "predict_regression_test = spatial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Test ##########################\n",
      "MALE test:.... 59496.127310202515\n",
      "RMSE test:.... 92299.98755954506\n",
      "MAPE test:.... 9.376750507099326\n",
      "################# Train ##########################\n",
      "MALE train:.... 59496.127310202515\n",
      "RMSE train:.... 91617.13646071764\n",
      "MAPE train:.... 8.30230942234849\n"
     ]
    }
   ],
   "source": [
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models benchmarking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = dataset.X_train,dataset.X_test,dataset.y_train,dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For X_train\n",
    "unique_X_train, index_X_train, counts_X_train = np.unique(X_train, axis=0, return_index=True, return_counts=True)\n",
    "duplicated_X_train = len(X_train) - len(unique_X_train)\n",
    "print(f\"Duplicated rows in X_train: {duplicated_X_train}\")\n",
    "\n",
    "# For X_test\n",
    "unique_X_test, index_X_test, counts_X_test = np.unique(X_test, axis=0, return_index=True, return_counts=True)\n",
    "duplicated_X_test = len(X_test) - len(unique_X_test)\n",
    "print(f\"Duplicated rows in X_test: {duplicated_X_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the mean absolute percentage error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "\n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [1, 10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [1000, 2000], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0, n_estimators=2000),\n",
    "        'params': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error((y_test), (y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score((y_test), (y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error((y_test), (y_pred_test))\n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train , y_test = embedded_train,embedded_test,dataset.y_train,dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3a12b150b8d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     },\n\u001b[0;32m     14\u001b[0m     'KNN': {\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[1;34m'model'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;34m'params'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     },\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store test set evaluation metrics for each model\n",
    "test_mae_list = {}\n",
    "test_mse_list = {}\n",
    "test_rmse_list = {}\n",
    "test_r2_list = {}\n",
    "test_mape_list = {}\n",
    "\n",
    "# Define the models and their respective parameter grids\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {'n_neighbors': [5, 10, 15, 20]}\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'max_depth': [5, 9, 12, 15]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {'n_estimators': [50, 100, 150], 'max_depth': [8, 12, 16]}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVR(),\n",
    "        'params': {'C': [10, 100], 'gamma': ['scale', 'auto']}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMRegressor(),\n",
    "        'params': {'n_estimators': [200,400,1000], 'learning_rate': [0.05]}\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0),\n",
    "        'params': {'depth': [ 8, 10], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor( learning_rate=0.05, random_state=42),\n",
    "        'params': {'max_depth': [5, 7, 9], 'learning_rate': [0.05],'n_estimators': [200,400,1000]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# For each model\n",
    "for name, model_info in models.items():\n",
    "    test_mae_list[name] = []\n",
    "    test_mse_list[name] = []\n",
    "    test_rmse_list[name] = []\n",
    "    test_r2_list[name] = []\n",
    "    test_mape_list[name] = []\n",
    "\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid = GridSearchCV(estimator=model_info['model'], param_grid=model_info['params'], cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "        grid_result = grid.fit(X_train_fold, y_train_fold)\n",
    "        best_model = grid_result.best_estimator_\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error((y_test), (y_pred_test))\n",
    "        test_mse = mean_squared_error(np.exp(y_test), np.exp(y_pred_test))\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_r2 = r2_score(np.exp(y_test), np.exp(y_pred_test))\n",
    "        test_mape = mean_absolute_percentage_error(np.exp(y_test), np.exp(y_pred_test))\n",
    "\n",
    "\n",
    "        # Store the test set metrics in the lists\n",
    "        test_mae_list[name].append(test_mae)\n",
    "        test_mse_list[name].append(test_mse)\n",
    "        test_rmse_list[name].append(test_rmse)\n",
    "        test_r2_list[name].append(test_r2)\n",
    "        test_mape_list[name].append(test_mape)\n",
    "\n",
    "\n",
    "    # Calculate the average and best metrics for the test set\n",
    "    avg_test_mae = np.mean(test_mae_list[name])\n",
    "    avg_test_mse = np.mean(test_mse_list[name])\n",
    "    avg_test_rmse = np.mean(test_rmse_list[name])\n",
    "    avg_test_r2 = np.mean(test_r2_list[name])\n",
    "    avg_test_mape = np.mean(test_mape_list[name])\n",
    "\n",
    "\n",
    "    best_test_mae = np.min(test_mae_list[name])\n",
    "    best_test_mse = np.min(test_mse_list[name])\n",
    "    best_test_rmse = np.min(test_rmse_list[name])\n",
    "    best_test_r2 = np.max(test_r2_list[name])\n",
    "    best_test_mape = np.min(test_mape_list[name])\n",
    " \n",
    "\n",
    "    print(f\"Test Set Evaluation for {name}\")\n",
    "    print(f\"Average Test MAE: {avg_test_mae}, Best Test MAE: {best_test_mae}\")\n",
    "    print(f\"Average Test MSE: {avg_test_mse}, Best Test MSE: {best_test_mse}\")\n",
    "    print(f\"Average Test RMSE: {avg_test_rmse}, Best Test RMSE: {best_test_rmse}\")\n",
    "    print(f\"Average Test R2: {avg_test_r2}, Best Test R2: {best_test_r2}\")\n",
    "    print(f\"Average Test MAPE: {avg_test_mape}, Best Test MAPE: {best_test_mape}\")\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying pca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MODEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
